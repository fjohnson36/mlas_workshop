{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Time Prediction Baseline\n",
    "Example notebook for reading and transforming install prediction data.\n",
    "\n",
    "Version 0.1.1\n",
    "(convert to python stand-alone with `jupyter nbconvert --to python baseline.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============LICENSE_START=======================================================\n",
    "# Apache-2.0\n",
    "# ===================================================================================\n",
    "# Copyright (C) 2019 AT&T Intellectual Property  All rights reserved.\n",
    "# ===================================================================================\n",
    "# This software file is distributed by AT&T\n",
    "# under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# This file is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ===============LICENSE_END=========================================================\n",
    "# Eric Zavesky, 03/22/19\n",
    "\n",
    "import pandas as pd  # data read\n",
    "import numpy as np\n",
    "from sklearn import preprocessing  # data ETL\n",
    "from sklearn.model_selection import train_test_split   # balanced partioning\n",
    "import os,sys  # file checks\n",
    "import pickle   # compressed results\n",
    "import gzip  # compression \n",
    "import yaml   # configuration file\n",
    "\n",
    "from sklearn.feature_extraction import text  # text processing\n",
    "from sklearn import ensemble  # random forest\n",
    "from sklearn import metrics  # final scoring\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV  # training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Options\n",
    "\n",
    "It's handy to include configuration options in a standard file that can be quickly modified and rerun if you're training something new.  Of course, you can always use command-line configurations as well, but a handy set of defaults in a human-readable file might be a bit easier when you're running things in notebooks.\n",
    "\n",
    "Here, we're using a simple [YAML](https://camel.readthedocs.io/en/latest/yamlref.html) file for our options which is human-readable, allows comments, and is well supported by other languages.\n",
    "\n",
    "To modify this program's operation, just open the file `config.yaml` in your editor of choice and rerun this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config.yaml'\n",
    "if not os.path.isfile(config_path):\n",
    "    print(\"Sorry, can't find the configuration file {}, aborting.\".format(config_path))\n",
    "    sys.exit(-1)\n",
    "config = yaml.safe_load(open(config_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "First, let's load our data to see if we need to perform any transform operations.  We will load and parse into rows and columns using the [pandas read_csv function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) to return a standardized [pandas dataframe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). \n",
    "\n",
    "Of course, you could use whatever library or load function you're used to, but these dataframes have nice interoperability properties with other libraries for learning and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(config[\"path\"][\"train_data\"]):\n",
    "    print(\"Sorry, can't find a raw input file ({} or {}), aborting.\".format(config[\"path\"][\"train_data\"]))\n",
    "    sys.exit(-1)\n",
    "\n",
    "df = {}\n",
    "df_train = pd.read_csv(config[\"path\"][\"train_data\"])\n",
    "# set the index\n",
    "df_train.set_index(\"row_id\", drop=True, inplace=True)\n",
    "\n",
    "print(\"Dimensionality of Training: {}\".format(df_train.shape))\n",
    "print(df_train.sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Preprocessing for this data will like convert some of our textual columns (`capbucket` and `capcat`) into numerical values.  Additionally, we can make sense of the `date` field with some other seasonal manipulationls.  Finally, since we're using `row_id` simply as a sample index, let's update our dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models[\"capbucket\"] = preprocessing.OrdinalEncoder() #text.CountVectorizer(tokenizer=lambda x: x.split(\"_\"))\n",
    "models[\"capcat\"] = text.CountVectorizer()\n",
    "\n",
    "\n",
    "# our main preprocessing function\n",
    "def preproc_data(models, df_test, df_train=None):\n",
    "    print(\"Test dimensionality before processing {}\".format(df_test.shape))\n",
    "\n",
    "    if df_train is not None:\n",
    "        # convert categorical/fixed text into numbers\n",
    "        # peel off the STATE, CITY, REGION from the bucket\n",
    "        tmp_feat = df_train[\"capbucket\"].str.split(\"_\", 3).values.tolist()\n",
    "        models[\"capbucket\"].fit(tmp_feat)\n",
    "        models[\"capcat\"].fit(df_train[\"capcat\"])\n",
    "\n",
    "    # convert the date into something more reasonable\n",
    "    print(\"Preprocessing vectorized 'date' ...\")\n",
    "    df_time = pd.to_datetime(df_test[\"date\"], format='%Y-%m-%d')\n",
    "    df_test[\"weekday\"] = df_time.dt.dayofweek   # grab the day of week\n",
    "    df_test[\"day\"] = df_time.dt.day   # grab the day of week\n",
    "    df_test[\"year\"] = df_time.dt.year   # grab the day of week\n",
    "    df_test[\"month\"] = df_time.dt.month   # grab the month of the year\n",
    "    del df_test[\"date\"]\n",
    "    print(\"... dimensionality after date processing {}\".format(df_test.shape))\n",
    "        \n",
    "    print(\"Preprocessing categorical data ...\")\n",
    "    # handle text encoding with categorical\n",
    "    tmp_feat = df_test[\"capbucket\"].str.split(\"_\", 3).values.tolist()\n",
    "    tmp_feat = models[\"capbucket\"].transform(tmp_feat)\n",
    "    col_tmp = [\"loc_{}\".format(x) for x in range(len(tmp_feat[0]))]\n",
    "    tmp_encode = pd.DataFrame(tmp_feat,  columns=col_tmp, index=df_test.index)\n",
    "    df_test = pd.concat([df_test, tmp_encode], axis=1, sort=False)\n",
    "    del df_test[\"capbucket\"]\n",
    "    print(\"... dimensionality after location processing {}\".format(df_test.shape))\n",
    "    # job encoding by term\n",
    "    col_tmp = [\"job_{}\".format(x) for x in models[\"capcat\"].get_feature_names()]\n",
    "    tmp_encode = pd.DataFrame(models[\"capcat\"].transform(df_test[\"capcat\"]).toarray(),  \n",
    "                              columns=col_tmp, index=df_test.index)\n",
    "    df_test = pd.concat([df_test, tmp_encode], axis=1, sort=False)\n",
    "    del df_test[\"capcat\"]\n",
    "    print(\"... dimensionality after job type processing {}\".format(df_test.shape))\n",
    "\n",
    "    # return trained/used model and test data\n",
    "    df_test = df_test.astype(float)\n",
    "    return models, df_test\n",
    "\n",
    "# pull out the target first, then run preprocessing\n",
    "Y = df_train[\"dailyCountSum\"].astype(float)\n",
    "X = df_train.copy()\n",
    "del X[\"dailyCountSum\"]\n",
    "    \n",
    "# do processing\n",
    "# models, X = preproc_data(models, X, df[\"X_train\"])  # what you SHOULD do for independent test samples\n",
    "models, X = preproc_data(models, X, X.copy())  # what we do, to use ALL of the training data\n",
    "# take a peek at our data now\n",
    "print(X.sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization and Scaling\n",
    "Let's take advantage of a [standard scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to get things into shape and between the ranges of `[0,1]`.\n",
    "\n",
    "After scaling, we quickly visualize the training samples and see that most of our features are reaonsable, except thos that have a flat/empty box.  Also, we can below that fields like `day` and `month` are numerically reduced to a range that is better for most classifiers to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and scale the train data in one pass\n",
    "if \"scaler\" not in models:  # avoid repeat run/train\n",
    "    models[\"scaler\"] = preprocessing.StandardScaler()\n",
    "    X = pd.DataFrame(models[\"scaler\"].fit_transform(X), columns=X.columns, index=X.index)\n",
    "# visualize the ranges of a few columns of data\n",
    "plot = X.boxplot(figsize=(12,6), rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "if config[\"training\"][\"model\"]==\"rf\":  # which classifier to try?\n",
    "    models[\"primary\"] = ensemble.RandomForestRegressor(n_estimators=1000, max_depth=3)\n",
    "    models[\"param\"] = {\"n_estimators\":(1000,), \"max_depth\":(3,)} #{\"n_estimators\":(50, 100, 200), \"max_depth\":(2,5)}\n",
    "elif config[\"training\"][\"model\"]==\"gbm\":\n",
    "    models[\"primary\"] = ensemble.GradientBoostingRegressor(n_estimators=500, max_depth=6,learning_rate=0.3, max_features=3)\n",
    "    models[\"param\"] = {\"n_estimators\":(500,), \"learning_rate\":(0.3,),\"max_features\": (3,), \"max_depth\":(6,) } # {\"n_estimators\":(50, 100, 200), \"max_features\": (2,), \"learning_rate\":(0.1, 0.2)}\n",
    "else:\n",
    "    raise Exception(\"Unknown training model {}, aborting now\".format(config[\"training\"][\"model\"]))\n",
    "clf = GridSearchCV(models[\"primary\"], models[\"param\"], cv=3, verbose=2, \n",
    "                   #n_jobs=1, scoring=config[\"training\"][\"scoring\"], \n",
    "                   n_jobs=config[\"training\"][\"threads\"], scoring=config[\"training\"][\"scoring\"], \n",
    "                   refit=config[\"training\"][\"scoring\"][0], return_train_score=True)\n",
    "print(\"Executing grid search ({})\".format(clf))\n",
    "scores = clf.fit(X, Y)\n",
    "models[\"best\"] = clf.best_estimator_\n",
    "print(clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models[\"best\"])\n",
    "for t in [\"train\", \"test\"]:\n",
    "    k = \"mean_{}_{}\".format(t, config[\"training\"][\"scoring\"][0])\n",
    "    print(\"{}: {}\".format(k, clf.cv_results_[k]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Test Data\n",
    "The mean performance scores above are helpful, but they may not exactly map to performance on a test set, but don't be discouraged. \n",
    "\n",
    "The last thing to do is evaluate on test data, which generally has these steps.\n",
    "1. Load the test data\n",
    "2. Preprocess the raw data to generate new features\n",
    "3. Evaluate the preprocessed features for direct evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, apply it on test data\n",
    "df_test = pd.read_csv(config[\"path\"][\"test_data\"])\n",
    "# set the index\n",
    "df_test.set_index(\"row_id\", drop=True, inplace=True)\n",
    "\n",
    "# do processing + prediction\n",
    "models, df_test = preproc_data(models, df_test)\n",
    "# normalize feature values\n",
    "df_test = pd.DataFrame(models[\"scaler\"].fit_transform(df_test), columns=df_test.columns, index=df_test.index)\n",
    "# predict values\n",
    "nd_predict = models[\"best\"].predict(df_test)\n",
    "print(\"Writing predictions to '{}'\".format(config[\"path\"][\"test_predictions\"]))\n",
    "pd.DataFrame(nd_predict, columns=[\"dailyCountSum\"], index=df_test.index).to_csv(\n",
    "    config[\"path\"][\"test_predictions\"], header=True,  index=True)\n",
    "\n",
    "# write results to file\n",
    "if os.path.isfile(config[\"path\"][\"test_labels\"]):\n",
    "    print(\"=== Special admin review with TEST data === \")\n",
    "    df_labels = pd.read_csv(config[\"path\"][\"test_labels\"])\n",
    "    df_labels[\"predict\"] = nd_predict\n",
    "    print(df_labels)\n",
    "    print(\"Test Score: {}\".format(metrics.mean_squared_error(\n",
    "        df_labels[\"dailyCountSum\"], df_labels[\"predict\"])))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to Submit!\n",
    "All done with evaluating the data and writing your predictions.  They should be saved in the `config[\"path\"][\"test_predictions\"]` file (by default, it's defined as `data/ss-2019-iefs-install-test_predictions.csv`).  Just pick up that file and submit it through the asessment interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# example code to shuffle from manicured ground truth!\n",
    "def gt_shuffle():\n",
    "    # read the test data and shift the index\n",
    "    df_test = pd.read_csv(config[\"path\"][\"test_data\"])\n",
    "    df_test.set_index(\"row_id\", drop=True, inplace=True)\n",
    "    # finally, apply it on test data\n",
    "    from sklearn import utils\n",
    "    df_test = utils.shuffle(df_test)\n",
    "    Y = df_test[\"dailyCountSum\"].astype(float)\n",
    "    del df_test[\"dailyCountSum\"]\n",
    "    # save out shuffled label data\n",
    "    Y.to_csv(config[\"path\"][\"test_labels\"], header=True, index=True)\n",
    "    df_test.to_csv(config[\"path\"][\"test_data\"], header=True, index=True)\n",
    "#gt_shuffle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
